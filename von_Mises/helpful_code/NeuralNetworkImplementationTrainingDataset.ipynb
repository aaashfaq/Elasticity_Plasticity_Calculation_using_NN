{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08931492-7f55-4b4d-b350-507eb45c9994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyDOE import lhs  # Latin Hypercube Sampling\n",
    "from scipy.optimize import newton\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Material constant ranges from Table 1\n",
    "material_constant_ranges = {\n",
    "    \"E\": [60000, 210000],  # Young's modulus in MPa\n",
    "    \"sigma_y\": [90, 1000],  # Yield stress in MPa\n",
    "    \"c1\": [1, 250],  # Kinematic hardening constants\n",
    "    \"c2\": [1, 250],\n",
    "    \"c3\": [1, 250],\n",
    "    \"gamma1\": [0, 10000],\n",
    "    \"gamma2\": [0, 10000],\n",
    "    \"gamma3\": [0, 10000],\n",
    "    \"b\": [1, 40],  # Isotropic hardening rate\n",
    "    \"Q\": [1, 150],  # Saturation value for isotropic hardening\n",
    "}\n",
    "\n",
    "# Generate material constants using Latin Hypercube Sampling\n",
    "def generate_material_constants_lhs(num_samples, ranges):\n",
    "    num_variables = len(ranges)\n",
    "    lhs_samples = lhs(num_variables, samples=num_samples)\n",
    "    material_constants = []\n",
    "\n",
    "    for i, (key, (low, high)) in enumerate(ranges.items()):\n",
    "        samples = lhs_samples[:, i] * (high - low) + low\n",
    "        material_constants.append(samples)\n",
    "\n",
    "    return np.column_stack(material_constants)\n",
    "\n",
    "# Generate strain history\n",
    "def generate_strain_history(num_samples, lb, ub):\n",
    "    strain_history = np.zeros(num_samples)\n",
    "    cumulative_strain = 0  # Start with zero cumulative strain\n",
    "\n",
    "    # First range: Accumulate small positive strain increments\n",
    "    for i in range(300):\n",
    "        increment = np.random.uniform(lb, ub)\n",
    "        cumulative_strain += increment\n",
    "        strain_history[i] = cumulative_strain\n",
    "\n",
    "    # Second range: Accumulate negative strain increments\n",
    "    for i in range(300, 900):\n",
    "        increment = np.random.uniform(lb, ub)\n",
    "        cumulative_strain -= increment\n",
    "        strain_history[i] = cumulative_strain\n",
    "\n",
    "    # Third range: Return to positive strain increments\n",
    "    for i in range(900, num_samples):\n",
    "        increment = np.random.uniform(lb, ub)\n",
    "        cumulative_strain += increment\n",
    "        strain_history[i] = cumulative_strain\n",
    "\n",
    "    return strain_history\n",
    "\n",
    "# Hooke's law (elastic predictor)\n",
    "def elastic_predictor(eps, eps_p, E, sigma_k1, sigma_k2, sigma_k3, sigma_i, sigma_y):\n",
    "    sigma_trial = E * (eps - eps_p)  # Trial stress\n",
    "    back_stress = sigma_k1 + sigma_k2 + sigma_k3\n",
    "    yield_function = np.abs(sigma_trial - back_stress) - (sigma_y + sigma_i)\n",
    "    return sigma_trial, yield_function\n",
    "\n",
    "# Update kinematic hardening rule\n",
    "def update_kinematic_hardening(sigma_k, eps_p_dot, c, gamma):\n",
    "    return (2.0 / 3.0) * c * eps_p_dot - gamma * sigma_k * np.abs(eps_p_dot)\n",
    "\n",
    "# Update isotropic hardening rule\n",
    "def update_isotropic_hardening(sigma_i, eps_p_dot, b, Q):\n",
    "    return b * (Q - sigma_i) * np.abs(eps_p_dot)\n",
    "\n",
    "# Return mapping algorithm\n",
    "def return_mapping(eps, eps_p, sigma_trial, yield_function, sigma_k1, sigma_k2, sigma_k3, sigma_i, c1, c2, c3, gamma1, gamma2, gamma3, b, Q, E, sigma_y):\n",
    "    if yield_function <= 0:\n",
    "        # Elastic step\n",
    "        return sigma_trial, eps_p, sigma_k1, sigma_k2, sigma_k3, sigma_i\n",
    "    else:\n",
    "        # Plastic corrector step\n",
    "        def plastic_residual(delta_gamma):\n",
    "            eps_p_dot = delta_gamma\n",
    "            back_stress = sigma_k1 + sigma_k2 + sigma_k3\n",
    "            sigma_updated = sigma_trial - E * delta_gamma\n",
    "            yield_function_updated = np.abs(sigma_trial - back_stress) - (sigma_y + sigma_i + b * delta_gamma)\n",
    "            return yield_function_updated\n",
    "\n",
    "        try:\n",
    "            delta_gamma = newton(plastic_residual, 1e-5, tol=1e-5, maxiter=50)  # Solve for plastic multiplier\n",
    "        except RuntimeError:\n",
    "            delta_gamma = 0.0  # If Newton-Raphson fails, assume no plastic deformation\n",
    "\n",
    "        eps_p += delta_gamma\n",
    "        sigma_k1 += update_kinematic_hardening(sigma_k1, delta_gamma, c1, gamma1)\n",
    "        sigma_k2 += update_kinematic_hardening(sigma_k2, delta_gamma, c2, gamma2)\n",
    "        sigma_k3 += update_kinematic_hardening(sigma_k3, delta_gamma, c3, gamma3)\n",
    "        sigma_i += update_isotropic_hardening(sigma_i, delta_gamma, b, Q)\n",
    "\n",
    "        # Final stress update\n",
    "        sigma_updated = sigma_trial - E * delta_gamma\n",
    "        return sigma_updated, eps_p, sigma_k1, sigma_k2, sigma_k3, sigma_i\n",
    "\n",
    "# Generate dataset\n",
    "def generate_dataset(num_samples, num_strain_samples, lb, ub, ranges):\n",
    "    material_constants = generate_material_constants_lhs(num_samples, ranges)\n",
    "    strain_history = generate_strain_history(num_strain_samples, lb, ub)\n",
    "    dataset = []\n",
    "\n",
    "    for constants in material_constants:\n",
    "        E, sigma_y, c1, c2, c3, gamma1, gamma2, gamma3, b, Q = constants\n",
    "        sigma_k1, sigma_k2, sigma_k3, sigma_i, eps_p = 0, 0, 0, 0, 0\n",
    "\n",
    "        for eps in strain_history:\n",
    "            # Elastic predictor\n",
    "            sigma_trial, yield_function = elastic_predictor(eps, eps_p, E, sigma_k1, sigma_k2, sigma_k3, sigma_i, sigma_y)\n",
    "\n",
    "            # Return mapping algorithm\n",
    "            sigma_updated, eps_p, sigma_k1, sigma_k2, sigma_k3, sigma_i = return_mapping(\n",
    "                eps, eps_p, sigma_trial, yield_function, sigma_k1, sigma_k2, sigma_k3, sigma_i,\n",
    "                c1, c2, c3, gamma1, gamma2, gamma3, b, Q, E, sigma_y\n",
    "            )\n",
    "\n",
    "            # Store the data\n",
    "            back_stress = sigma_k1 + sigma_k2 + sigma_k3\n",
    "            trial_phi = np.abs(sigma_trial - back_stress) - (sigma_y + sigma_i)\n",
    "            dataset.append([\n",
    "                E, sigma_y, c1, gamma1, c2, gamma2, c3, gamma3, b, Q, trial_phi, eps, sigma_updated, np.abs(eps_p)\n",
    "            ])\n",
    "\n",
    "    return np.array(dataset)\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "def save_dataset_to_csv(dataset, filename=\"generated_dataset_training20.11.csv\"):\n",
    "    columns = [E, sigma_y, c[0],gamma[0], c[1],gamma[1], c[2],gamma[2],\n",
    "                b, Q, trial_phi,\n",
    "                strain,          # Strain\n",
    "                stress_rm,    # Stress from Return Mapping\n",
    "                plastic_strain]\n",
    "    df = pd.DataFrame(dataset, columns=columns)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Dataset saved to {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffce04f1-c175-4c52-ab91-df0f6a3d08ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "def split_dataset(X, y):\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9daf92-757d-449d-88df-b39f67c448cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(data, scaler=None):\n",
    "    if scaler is None:\n",
    "        scaler = MinMaxScaler()\n",
    "        normalized_data = scaler.fit_transform(data)\n",
    "    else:\n",
    "        normalized_data = scaler.transform(data)\n",
    "    return normalized_data, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dc7e41a-b6af-4cdb-ad84-47e0dcae591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network\n",
    "def build_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(10, activation='sigmoid', input_shape=(input_dim,)),  # Use 10 neurons, sigmoid activation\n",
    "        Dense(1, activation='linear')     # Linear activation for the output\n",
    "    ])\n",
    "    custom_adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "    model.compile(optimizer=custom_adam, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdff6827-6e8a-4d2f-8149-d1e1a9982c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "def plot_loss(history, filename='loss_curve.png'):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    #plt.savefig(filename)  # Save the plot as an image file\n",
    "    #plt.close()  # Close the plot to avoid displaying it in the notebook\n",
    "    #print(f\"Loss curve saved as {filename}\")\n",
    "\n",
    "# Plot predicted vs original values\n",
    "def plot_predicted_vs_actual(y_test, y_pred, filename='predicted_vs_actual.png'):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(y_test, label='Original Values', color='blue')\n",
    "    plt.plot(y_pred, label='Predicted Values', color='red', linestyle='--')\n",
    "    plt.xlabel('Sample index')\n",
    "    plt.ylabel('Plastic Strain')\n",
    "    plt.title('Predicted vs. Original Plastic Strain')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    plt.savefig('predicted_vs_actual')  # Save the plot as an image file\n",
    "    plt.close()  # Close the plot to avoid displaying it in the notebookLHSLHS\n",
    "    print(f\"Plot saved as {'predicted_vs_actual'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0100d27-348d-4f6a-a539-dc902459c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = generate_dataset(num_samples=500, num_strain_samples=1500, lb=0.0001,ub=0.0002, ranges=material_constant_ranges)\n",
    "#test1 = generate_dataset(lb=0,ub=0.0001, num_strain_samples=1500)\n",
    "#test2 = generate_dataset(lb=0.0002,ub=0.0004, num_strain_samples=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1c93863-269f-47b1-a45f-52f2e2ee0655",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['E', 'sigma_y', 'c[0]','gamma[0]', 'c[1]','gamma[1]', 'c[2]','gamma[2]','b', 'Q', 'trial_phi',\n",
    "            'strain',          # Strain\n",
    "            'stress_rm',    # Stress from Return Mapping\n",
    "            'plastic_strain']\n",
    "df = pd.DataFrame(training, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fd40069-e2eb-4224-87ba-ea63fcb2cdc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>sigma_y</th>\n",
       "      <th>c[0]</th>\n",
       "      <th>gamma[0]</th>\n",
       "      <th>c[1]</th>\n",
       "      <th>gamma[1]</th>\n",
       "      <th>c[2]</th>\n",
       "      <th>gamma[2]</th>\n",
       "      <th>b</th>\n",
       "      <th>Q</th>\n",
       "      <th>trial_phi</th>\n",
       "      <th>strain</th>\n",
       "      <th>stress_rm</th>\n",
       "      <th>plastic_strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-2.920841e+02</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>1.489151e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-2.661035e+02</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>4.087213e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-2.469242e+02</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>6.005147e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-2.244893e+02</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>8.248637e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-2.055143e+02</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>1.014613e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-1.813919e+02</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>1.255838e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-1.614360e+02</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>1.455397e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-1.395704e+02</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>1.674053e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-1.229588e+02</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>1.840168e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-9.450165e+01</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>2.124740e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-6.573221e+01</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>2.412434e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-4.903879e+01</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>2.579369e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-3.065131e+01</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>2.763243e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-5.060479e+00</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>3.019152e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>-3.870182e+02</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>-1.019682e+05</td>\n",
       "      <td>7.038080e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>8.841299e+09</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>-6.598852e+08</td>\n",
       "      <td>4.540309e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>2.408984e+22</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>-5.304091e+13</td>\n",
       "      <td>3.649453e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>2.408984e+22</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>-5.304091e+13</td>\n",
       "      <td>3.649453e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>2.408984e+22</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>-5.304091e+13</td>\n",
       "      <td>3.649453e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>145339.342094</td>\n",
       "      <td>306.975655</td>\n",
       "      <td>239.725461</td>\n",
       "      <td>6079.799944</td>\n",
       "      <td>159.266406</td>\n",
       "      <td>8804.549894</td>\n",
       "      <td>168.89836</td>\n",
       "      <td>7613.05362</td>\n",
       "      <td>22.41875</td>\n",
       "      <td>8.640849</td>\n",
       "      <td>2.408984e+22</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>-5.304091e+13</td>\n",
       "      <td>3.649453e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                E     sigma_y        c[0]     gamma[0]        c[1]  \\\n",
       "0   145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "1   145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "2   145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "3   145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "4   145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "5   145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "6   145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "7   145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "8   145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "9   145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "10  145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "11  145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "12  145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "13  145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "14  145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "15  145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "16  145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "17  145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "18  145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "19  145339.342094  306.975655  239.725461  6079.799944  159.266406   \n",
       "\n",
       "       gamma[1]       c[2]    gamma[2]         b         Q     trial_phi  \\\n",
       "0   8804.549894  168.89836  7613.05362  22.41875  8.640849 -2.920841e+02   \n",
       "1   8804.549894  168.89836  7613.05362  22.41875  8.640849 -2.661035e+02   \n",
       "2   8804.549894  168.89836  7613.05362  22.41875  8.640849 -2.469242e+02   \n",
       "3   8804.549894  168.89836  7613.05362  22.41875  8.640849 -2.244893e+02   \n",
       "4   8804.549894  168.89836  7613.05362  22.41875  8.640849 -2.055143e+02   \n",
       "5   8804.549894  168.89836  7613.05362  22.41875  8.640849 -1.813919e+02   \n",
       "6   8804.549894  168.89836  7613.05362  22.41875  8.640849 -1.614360e+02   \n",
       "7   8804.549894  168.89836  7613.05362  22.41875  8.640849 -1.395704e+02   \n",
       "8   8804.549894  168.89836  7613.05362  22.41875  8.640849 -1.229588e+02   \n",
       "9   8804.549894  168.89836  7613.05362  22.41875  8.640849 -9.450165e+01   \n",
       "10  8804.549894  168.89836  7613.05362  22.41875  8.640849 -6.573221e+01   \n",
       "11  8804.549894  168.89836  7613.05362  22.41875  8.640849 -4.903879e+01   \n",
       "12  8804.549894  168.89836  7613.05362  22.41875  8.640849 -3.065131e+01   \n",
       "13  8804.549894  168.89836  7613.05362  22.41875  8.640849 -5.060479e+00   \n",
       "14  8804.549894  168.89836  7613.05362  22.41875  8.640849 -3.870182e+02   \n",
       "15  8804.549894  168.89836  7613.05362  22.41875  8.640849  8.841299e+09   \n",
       "16  8804.549894  168.89836  7613.05362  22.41875  8.640849  2.408984e+22   \n",
       "17  8804.549894  168.89836  7613.05362  22.41875  8.640849  2.408984e+22   \n",
       "18  8804.549894  168.89836  7613.05362  22.41875  8.640849  2.408984e+22   \n",
       "19  8804.549894  168.89836  7613.05362  22.41875  8.640849  2.408984e+22   \n",
       "\n",
       "      strain     stress_rm  plastic_strain  \n",
       "0   0.000102  1.489151e+01    0.000000e+00  \n",
       "1   0.000281  4.087213e+01    0.000000e+00  \n",
       "2   0.000413  6.005147e+01    0.000000e+00  \n",
       "3   0.000568  8.248637e+01    0.000000e+00  \n",
       "4   0.000698  1.014613e+02    0.000000e+00  \n",
       "5   0.000864  1.255838e+02    0.000000e+00  \n",
       "6   0.001001  1.455397e+02    0.000000e+00  \n",
       "7   0.001152  1.674053e+02    0.000000e+00  \n",
       "8   0.001266  1.840168e+02    0.000000e+00  \n",
       "9   0.001462  2.124740e+02    0.000000e+00  \n",
       "10  0.001660  2.412434e+02    0.000000e+00  \n",
       "11  0.001775  2.579369e+02    0.000000e+00  \n",
       "12  0.001901  2.763243e+02    0.000000e+00  \n",
       "13  0.002077  3.019152e+02    0.000000e+00  \n",
       "14  0.002221 -1.019682e+05    7.038080e-01  \n",
       "15  0.002352 -6.598852e+08    4.540309e+03  \n",
       "16  0.002546 -5.304091e+13    3.649453e+08  \n",
       "17  0.002660 -5.304091e+13    3.649453e+08  \n",
       "18  0.002766 -5.304091e+13    3.649453e+08  \n",
       "19  0.002908 -5.304091e+13    3.649453e+08  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "350e5b77-56b6-43ee-a85d-fc6189b7d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = training[:, :-3]  # Features (E, sigma_y, c1, c2, c3, gamma1, gamma2, gamma3, b, Q, strain)\n",
    "y = training[:, -1]   # Targets (plastic_strain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd87ef9c-24a8-4e69-8bff-20aef1810f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized, scaler_X= normalize_dataset(X)\n",
    "y = y.reshape(-1, 1)\n",
    "y_normalized, scaler_y= normalize_dataset(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bbb16d4-93f9-435e-b135-fdcb104529b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the neural network model...\n",
      "Training the model...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uashfaq/anaconda3/envs/elasticity/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - loss: 0.3056 - mae: 0.4368 - val_loss: 0.0913 - val_mae: 0.2560\n",
      "Epoch 2/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0857 - mae: 0.2500 - val_loss: 0.0826 - val_mae: 0.2470\n",
      "Epoch 3/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0802 - mae: 0.2444 - val_loss: 0.0775 - val_mae: 0.2417\n",
      "Epoch 4/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.0771 - mae: 0.2413 - val_loss: 0.0751 - val_mae: 0.2389\n",
      "Epoch 5/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0753 - mae: 0.2391 - val_loss: 0.0738 - val_mae: 0.2372\n",
      "Epoch 6/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0744 - mae: 0.2379 - val_loss: 0.0730 - val_mae: 0.2357\n",
      "Epoch 7/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0735 - mae: 0.2362 - val_loss: 0.0722 - val_mae: 0.2343\n",
      "Epoch 8/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0727 - mae: 0.2347 - val_loss: 0.0714 - val_mae: 0.2322\n",
      "Epoch 9/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0722 - mae: 0.2334 - val_loss: 0.0709 - val_mae: 0.2303\n",
      "Epoch 10/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0716 - mae: 0.2314 - val_loss: 0.0706 - val_mae: 0.2288\n",
      "Epoch 11/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.0715 - mae: 0.2304 - val_loss: 0.0706 - val_mae: 0.2281\n",
      "Epoch 12/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0717 - mae: 0.2304 - val_loss: 0.0705 - val_mae: 0.2278\n",
      "Epoch 13/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.0713 - mae: 0.2293 - val_loss: 0.0707 - val_mae: 0.2283\n",
      "Epoch 14/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0713 - mae: 0.2293 - val_loss: 0.0705 - val_mae: 0.2277\n",
      "Epoch 15/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.0715 - mae: 0.2296 - val_loss: 0.0705 - val_mae: 0.2277\n",
      "Epoch 16/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0712 - mae: 0.2290 - val_loss: 0.0705 - val_mae: 0.2275\n",
      "Epoch 17/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0713 - mae: 0.2291 - val_loss: 0.0706 - val_mae: 0.2280\n",
      "Epoch 18/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.0714 - mae: 0.2295 - val_loss: 0.0705 - val_mae: 0.2277\n",
      "Epoch 19/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.0713 - mae: 0.2292 - val_loss: 0.0705 - val_mae: 0.2274\n",
      "Epoch 20/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.0713 - mae: 0.2292 - val_loss: 0.0705 - val_mae: 0.2275\n",
      "Epoch 21/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - loss: 0.0714 - mae: 0.2295 - val_loss: 0.0706 - val_mae: 0.2272\n",
      "Epoch 22/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.0716 - mae: 0.2298 - val_loss: 0.0705 - val_mae: 0.2274\n",
      "Epoch 23/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 0.0713 - mae: 0.2291 - val_loss: 0.0705 - val_mae: 0.2275\n",
      "Epoch 24/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0713 - mae: 0.2291 - val_loss: 0.0705 - val_mae: 0.2275\n",
      "Epoch 25/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.0713 - mae: 0.2292 - val_loss: 0.0705 - val_mae: 0.2276\n",
      "Epoch 26/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.0713 - mae: 0.2293 - val_loss: 0.0705 - val_mae: 0.2274\n",
      "Epoch 27/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0713 - mae: 0.2292 - val_loss: 0.0705 - val_mae: 0.2277\n",
      "Epoch 28/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.0713 - mae: 0.2292 - val_loss: 0.0705 - val_mae: 0.2276\n",
      "Epoch 29/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0713 - mae: 0.2291 - val_loss: 0.0705 - val_mae: 0.2278\n",
      "Epoch 30/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - loss: 0.0715 - mae: 0.2296 - val_loss: 0.0705 - val_mae: 0.2276\n",
      "Epoch 31/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - loss: 0.0712 - mae: 0.2289 - val_loss: 0.0704 - val_mae: 0.2274\n",
      "Epoch 32/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.0712 - mae: 0.2289 - val_loss: 0.0705 - val_mae: 0.2271\n",
      "Epoch 33/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.0711 - mae: 0.2288 - val_loss: 0.0705 - val_mae: 0.2278\n",
      "Epoch 34/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.0711 - mae: 0.2287 - val_loss: 0.0704 - val_mae: 0.2272\n",
      "Epoch 35/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.0711 - mae: 0.2289 - val_loss: 0.0704 - val_mae: 0.2271\n",
      "Epoch 36/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.0712 - mae: 0.2290 - val_loss: 0.0704 - val_mae: 0.2275\n",
      "Epoch 37/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - loss: 0.0713 - mae: 0.2292 - val_loss: 0.0704 - val_mae: 0.2273\n",
      "Epoch 38/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.0713 - mae: 0.2291 - val_loss: 0.0704 - val_mae: 0.2272\n",
      "Epoch 39/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.0711 - mae: 0.2287 - val_loss: 0.0704 - val_mae: 0.2271\n",
      "Epoch 40/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.0713 - mae: 0.2292 - val_loss: 0.0704 - val_mae: 0.2272\n",
      "Epoch 41/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.0711 - mae: 0.2288 - val_loss: 0.0704 - val_mae: 0.2271\n",
      "Epoch 42/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.0713 - mae: 0.2291 - val_loss: 0.0704 - val_mae: 0.2275\n",
      "Epoch 43/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.0711 - mae: 0.2286 - val_loss: 0.0703 - val_mae: 0.2270\n",
      "Epoch 44/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.0711 - mae: 0.2286 - val_loss: 0.0704 - val_mae: 0.2267\n",
      "Epoch 45/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - loss: 0.0712 - mae: 0.2289 - val_loss: 0.0703 - val_mae: 0.2273\n",
      "Epoch 46/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.0712 - mae: 0.2289 - val_loss: 0.0703 - val_mae: 0.2270\n",
      "Epoch 47/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.0711 - mae: 0.2287 - val_loss: 0.0703 - val_mae: 0.2273\n",
      "Epoch 48/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - loss: 0.0710 - mae: 0.2285 - val_loss: 0.0705 - val_mae: 0.2279\n",
      "Epoch 49/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0711 - mae: 0.2287 - val_loss: 0.0703 - val_mae: 0.2272\n",
      "Epoch 50/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.0711 - mae: 0.2288 - val_loss: 0.0703 - val_mae: 0.2266\n",
      "Epoch 51/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.0709 - mae: 0.2284 - val_loss: 0.0703 - val_mae: 0.2272\n",
      "Epoch 52/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.0709 - mae: 0.2283 - val_loss: 0.0702 - val_mae: 0.2267\n",
      "Epoch 53/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0710 - mae: 0.2284 - val_loss: 0.0702 - val_mae: 0.2270\n",
      "Epoch 54/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - loss: 0.0709 - mae: 0.2283 - val_loss: 0.0702 - val_mae: 0.2264\n",
      "Epoch 55/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.0709 - mae: 0.2283 - val_loss: 0.0701 - val_mae: 0.2264\n",
      "Epoch 56/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.0711 - mae: 0.2286 - val_loss: 0.0702 - val_mae: 0.2263\n",
      "Epoch 57/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 0.0709 - mae: 0.2282 - val_loss: 0.0701 - val_mae: 0.2267\n",
      "Epoch 58/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.0708 - mae: 0.2281 - val_loss: 0.0700 - val_mae: 0.2265\n",
      "Epoch 59/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.0708 - mae: 0.2283 - val_loss: 0.0701 - val_mae: 0.2261\n",
      "Epoch 60/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0709 - mae: 0.2282 - val_loss: 0.0700 - val_mae: 0.2262\n",
      "Epoch 61/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 0.0708 - mae: 0.2280 - val_loss: 0.0700 - val_mae: 0.2262\n",
      "Epoch 62/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.0708 - mae: 0.2281 - val_loss: 0.0700 - val_mae: 0.2261\n",
      "Epoch 63/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.0707 - mae: 0.2279 - val_loss: 0.0700 - val_mae: 0.2265\n",
      "Epoch 64/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0708 - mae: 0.2280 - val_loss: 0.0700 - val_mae: 0.2259\n",
      "Epoch 65/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - loss: 0.0707 - mae: 0.2279 - val_loss: 0.0699 - val_mae: 0.2263\n",
      "Epoch 66/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0708 - mae: 0.2279 - val_loss: 0.0699 - val_mae: 0.2264\n",
      "Epoch 67/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0707 - mae: 0.2278 - val_loss: 0.0699 - val_mae: 0.2262\n",
      "Epoch 68/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0706 - mae: 0.2277 - val_loss: 0.0699 - val_mae: 0.2257\n",
      "Epoch 69/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.0709 - mae: 0.2281 - val_loss: 0.0699 - val_mae: 0.2261\n",
      "Epoch 70/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.0707 - mae: 0.2279 - val_loss: 0.0698 - val_mae: 0.2258\n",
      "Epoch 71/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - loss: 0.0706 - mae: 0.2276 - val_loss: 0.0698 - val_mae: 0.2260\n",
      "Epoch 72/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796us/step - loss: 0.0708 - mae: 0.2282 - val_loss: 0.0698 - val_mae: 0.2258\n",
      "Epoch 73/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step - loss: 0.0707 - mae: 0.2278 - val_loss: 0.0699 - val_mae: 0.2254\n",
      "Epoch 74/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 0.0707 - mae: 0.2277 - val_loss: 0.0698 - val_mae: 0.2257\n",
      "Epoch 75/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - loss: 0.0706 - mae: 0.2276 - val_loss: 0.0698 - val_mae: 0.2258\n",
      "Epoch 76/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.0706 - mae: 0.2276 - val_loss: 0.0697 - val_mae: 0.2259\n",
      "Epoch 77/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.0705 - mae: 0.2272 - val_loss: 0.0699 - val_mae: 0.2253\n",
      "Epoch 78/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.0706 - mae: 0.2275 - val_loss: 0.0697 - val_mae: 0.2254\n",
      "Epoch 79/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.0705 - mae: 0.2272 - val_loss: 0.0698 - val_mae: 0.2252\n",
      "Epoch 80/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 0.0706 - mae: 0.2276 - val_loss: 0.0697 - val_mae: 0.2255\n",
      "Epoch 81/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.0707 - mae: 0.2277 - val_loss: 0.0697 - val_mae: 0.2255\n",
      "Epoch 82/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.0706 - mae: 0.2276 - val_loss: 0.0697 - val_mae: 0.2258\n",
      "Epoch 83/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - loss: 0.0705 - mae: 0.2273 - val_loss: 0.0699 - val_mae: 0.2250\n",
      "Epoch 84/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - loss: 0.0704 - mae: 0.2271 - val_loss: 0.0697 - val_mae: 0.2253\n",
      "Epoch 85/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.0706 - mae: 0.2275 - val_loss: 0.0697 - val_mae: 0.2253\n",
      "Epoch 86/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0705 - mae: 0.2272 - val_loss: 0.0696 - val_mae: 0.2255\n",
      "Epoch 87/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.0704 - mae: 0.2272 - val_loss: 0.0697 - val_mae: 0.2250\n",
      "Epoch 88/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.0707 - mae: 0.2277 - val_loss: 0.0696 - val_mae: 0.2251\n",
      "Epoch 89/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0704 - mae: 0.2272 - val_loss: 0.0696 - val_mae: 0.2252\n",
      "Epoch 90/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0705 - mae: 0.2273 - val_loss: 0.0696 - val_mae: 0.2251\n",
      "Epoch 91/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 0.0706 - mae: 0.2274 - val_loss: 0.0696 - val_mae: 0.2252\n",
      "Epoch 92/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0704 - mae: 0.2272 - val_loss: 0.0696 - val_mae: 0.2251\n",
      "Epoch 93/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0705 - mae: 0.2272 - val_loss: 0.0696 - val_mae: 0.2253\n",
      "Epoch 94/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.0705 - mae: 0.2273 - val_loss: 0.0696 - val_mae: 0.2256\n",
      "Epoch 95/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.0705 - mae: 0.2273 - val_loss: 0.0696 - val_mae: 0.2253\n",
      "Epoch 96/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0704 - mae: 0.2269 - val_loss: 0.0696 - val_mae: 0.2252\n",
      "Epoch 97/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0705 - mae: 0.2271 - val_loss: 0.0696 - val_mae: 0.2250\n",
      "Epoch 98/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.0705 - mae: 0.2273 - val_loss: 0.0696 - val_mae: 0.2252\n",
      "Epoch 99/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.0704 - mae: 0.2271 - val_loss: 0.0696 - val_mae: 0.2251\n",
      "Epoch 100/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0703 - mae: 0.2269 - val_loss: 0.0696 - val_mae: 0.2249\n",
      "Epoch 101/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.0704 - mae: 0.2271 - val_loss: 0.0695 - val_mae: 0.2251\n",
      "Epoch 102/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0704 - mae: 0.2269 - val_loss: 0.0696 - val_mae: 0.2248\n",
      "Epoch 103/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0704 - mae: 0.2270 - val_loss: 0.0698 - val_mae: 0.2245\n",
      "Epoch 104/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.0704 - mae: 0.2269 - val_loss: 0.0696 - val_mae: 0.2257\n",
      "Epoch 105/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 0.0704 - mae: 0.2269 - val_loss: 0.0696 - val_mae: 0.2248\n",
      "Epoch 106/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.0703 - mae: 0.2267 - val_loss: 0.0696 - val_mae: 0.2255\n",
      "Epoch 107/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0706 - mae: 0.2273 - val_loss: 0.0695 - val_mae: 0.2249\n",
      "Epoch 108/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - loss: 0.0703 - mae: 0.2268 - val_loss: 0.0695 - val_mae: 0.2248\n",
      "Epoch 109/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.0702 - mae: 0.2266 - val_loss: 0.0696 - val_mae: 0.2246\n",
      "Epoch 110/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.0703 - mae: 0.2267 - val_loss: 0.0695 - val_mae: 0.2249\n",
      "Epoch 111/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0703 - mae: 0.2268 - val_loss: 0.0695 - val_mae: 0.2255\n",
      "Epoch 112/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.0704 - mae: 0.2270 - val_loss: 0.0696 - val_mae: 0.2257\n",
      "Epoch 113/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.0705 - mae: 0.2271 - val_loss: 0.0695 - val_mae: 0.2251\n",
      "Epoch 114/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.0704 - mae: 0.2270 - val_loss: 0.0696 - val_mae: 0.2258\n",
      "Epoch 115/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0704 - mae: 0.2271 - val_loss: 0.0695 - val_mae: 0.2250\n",
      "Epoch 116/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0704 - mae: 0.2270 - val_loss: 0.0695 - val_mae: 0.2246\n",
      "Epoch 117/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0703 - mae: 0.2267 - val_loss: 0.0695 - val_mae: 0.2250\n",
      "Epoch 118/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.0702 - mae: 0.2266 - val_loss: 0.0695 - val_mae: 0.2247\n",
      "Epoch 119/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0703 - mae: 0.2266 - val_loss: 0.0696 - val_mae: 0.2245\n",
      "Epoch 120/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.0702 - mae: 0.2266 - val_loss: 0.0697 - val_mae: 0.2244\n",
      "Epoch 121/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0703 - mae: 0.2266 - val_loss: 0.0695 - val_mae: 0.2251\n",
      "Epoch 122/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.0702 - mae: 0.2266 - val_loss: 0.0695 - val_mae: 0.2248\n",
      "Epoch 123/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.0703 - mae: 0.2268 - val_loss: 0.0695 - val_mae: 0.2246\n",
      "Epoch 124/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0702 - mae: 0.2266 - val_loss: 0.0694 - val_mae: 0.2249\n",
      "Epoch 125/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.0702 - mae: 0.2266 - val_loss: 0.0694 - val_mae: 0.2248\n",
      "Epoch 126/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0704 - mae: 0.2270 - val_loss: 0.0694 - val_mae: 0.2250\n",
      "Epoch 127/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0702 - mae: 0.2266 - val_loss: 0.0696 - val_mae: 0.2244\n",
      "Epoch 128/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.0703 - mae: 0.2268 - val_loss: 0.0695 - val_mae: 0.2253\n",
      "Epoch 129/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0702 - mae: 0.2266 - val_loss: 0.0695 - val_mae: 0.2253\n",
      "Epoch 130/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.0702 - mae: 0.2264 - val_loss: 0.0694 - val_mae: 0.2247\n",
      "Epoch 131/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0702 - mae: 0.2266 - val_loss: 0.0694 - val_mae: 0.2252\n",
      "Epoch 132/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0703 - mae: 0.2267 - val_loss: 0.0694 - val_mae: 0.2249\n",
      "Epoch 133/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0703 - mae: 0.2267 - val_loss: 0.0694 - val_mae: 0.2249\n",
      "Epoch 134/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.0703 - mae: 0.2266 - val_loss: 0.0694 - val_mae: 0.2246\n",
      "Epoch 135/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0705 - mae: 0.2271 - val_loss: 0.0694 - val_mae: 0.2247\n",
      "Epoch 136/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0704 - mae: 0.2268 - val_loss: 0.0696 - val_mae: 0.2259\n",
      "Epoch 137/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.0703 - mae: 0.2267 - val_loss: 0.0694 - val_mae: 0.2245\n",
      "Epoch 138/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0703 - mae: 0.2267 - val_loss: 0.0694 - val_mae: 0.2247\n",
      "Epoch 139/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.0703 - mae: 0.2267 - val_loss: 0.0694 - val_mae: 0.2247\n",
      "Epoch 140/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0702 - mae: 0.2266 - val_loss: 0.0694 - val_mae: 0.2248\n",
      "Epoch 141/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0702 - mae: 0.2265 - val_loss: 0.0694 - val_mae: 0.2246\n",
      "Epoch 142/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.0701 - mae: 0.2262 - val_loss: 0.0694 - val_mae: 0.2247\n",
      "Epoch 143/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.0701 - mae: 0.2263 - val_loss: 0.0694 - val_mae: 0.2253\n",
      "Epoch 144/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.0703 - mae: 0.2266 - val_loss: 0.0694 - val_mae: 0.2244\n",
      "Epoch 145/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0702 - mae: 0.2267 - val_loss: 0.0694 - val_mae: 0.2251\n",
      "Epoch 146/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0702 - mae: 0.2265 - val_loss: 0.0693 - val_mae: 0.2245\n",
      "Epoch 147/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0701 - mae: 0.2264 - val_loss: 0.0694 - val_mae: 0.2244\n",
      "Epoch 148/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.0702 - mae: 0.2264 - val_loss: 0.0694 - val_mae: 0.2242\n",
      "Epoch 149/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.0703 - mae: 0.2267 - val_loss: 0.0693 - val_mae: 0.2246\n",
      "Epoch 150/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.0703 - mae: 0.2266 - val_loss: 0.0693 - val_mae: 0.2243\n",
      "Epoch 151/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0695 - val_mae: 0.2256\n",
      "Epoch 152/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0703 - mae: 0.2267 - val_loss: 0.0693 - val_mae: 0.2247\n",
      "Epoch 153/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.0701 - mae: 0.2262 - val_loss: 0.0694 - val_mae: 0.2249\n",
      "Epoch 154/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.0702 - mae: 0.2265 - val_loss: 0.0693 - val_mae: 0.2244\n",
      "Epoch 155/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.0701 - mae: 0.2262 - val_loss: 0.0693 - val_mae: 0.2248\n",
      "Epoch 156/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0701 - mae: 0.2262 - val_loss: 0.0693 - val_mae: 0.2250\n",
      "Epoch 157/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 0.0702 - mae: 0.2265 - val_loss: 0.0694 - val_mae: 0.2251\n",
      "Epoch 158/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.0702 - mae: 0.2265 - val_loss: 0.0693 - val_mae: 0.2247\n",
      "Epoch 159/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.0702 - mae: 0.2264 - val_loss: 0.0694 - val_mae: 0.2241\n",
      "Epoch 160/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0701 - mae: 0.2262 - val_loss: 0.0693 - val_mae: 0.2245\n",
      "Epoch 161/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0702 - mae: 0.2264 - val_loss: 0.0693 - val_mae: 0.2250\n",
      "Epoch 162/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0703 - mae: 0.2267 - val_loss: 0.0693 - val_mae: 0.2248\n",
      "Epoch 163/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.0703 - mae: 0.2266 - val_loss: 0.0693 - val_mae: 0.2245\n",
      "Epoch 164/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0703 - mae: 0.2266 - val_loss: 0.0693 - val_mae: 0.2244\n",
      "Epoch 165/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.0702 - mae: 0.2265 - val_loss: 0.0693 - val_mae: 0.2246\n",
      "Epoch 166/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.0701 - mae: 0.2262 - val_loss: 0.0693 - val_mae: 0.2245\n",
      "Epoch 167/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.0702 - mae: 0.2264 - val_loss: 0.0693 - val_mae: 0.2244\n",
      "Epoch 168/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 0.0704 - mae: 0.2268 - val_loss: 0.0693 - val_mae: 0.2246\n",
      "Epoch 169/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 0.0701 - mae: 0.2263 - val_loss: 0.0693 - val_mae: 0.2243\n",
      "Epoch 170/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0700 - mae: 0.2261 - val_loss: 0.0693 - val_mae: 0.2244\n",
      "Epoch 171/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 0.0701 - mae: 0.2263 - val_loss: 0.0693 - val_mae: 0.2243\n",
      "Epoch 172/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.0702 - mae: 0.2263 - val_loss: 0.0693 - val_mae: 0.2244\n",
      "Epoch 173/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0693 - val_mae: 0.2241\n",
      "Epoch 174/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.0702 - mae: 0.2265 - val_loss: 0.0693 - val_mae: 0.2247\n",
      "Epoch 175/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.0701 - mae: 0.2264 - val_loss: 0.0692 - val_mae: 0.2243\n",
      "Epoch 176/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 0.0703 - mae: 0.2266 - val_loss: 0.0692 - val_mae: 0.2243\n",
      "Epoch 177/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0702 - mae: 0.2263 - val_loss: 0.0693 - val_mae: 0.2242\n",
      "Epoch 178/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.0702 - mae: 0.2265 - val_loss: 0.0693 - val_mae: 0.2240\n",
      "Epoch 179/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 0.0702 - mae: 0.2265 - val_loss: 0.0692 - val_mae: 0.2245\n",
      "Epoch 180/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - loss: 0.0702 - mae: 0.2265 - val_loss: 0.0692 - val_mae: 0.2245\n",
      "Epoch 181/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - loss: 0.0701 - mae: 0.2263 - val_loss: 0.0693 - val_mae: 0.2250\n",
      "Epoch 182/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.0699 - mae: 0.2260 - val_loss: 0.0693 - val_mae: 0.2250\n",
      "Epoch 183/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - loss: 0.0701 - mae: 0.2264 - val_loss: 0.0692 - val_mae: 0.2246\n",
      "Epoch 184/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.0699 - mae: 0.2259 - val_loss: 0.0693 - val_mae: 0.2251\n",
      "Epoch 185/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.0701 - mae: 0.2262 - val_loss: 0.0693 - val_mae: 0.2249\n",
      "Epoch 186/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step - loss: 0.0702 - mae: 0.2266 - val_loss: 0.0692 - val_mae: 0.2248\n",
      "Epoch 187/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 0.0702 - mae: 0.2264 - val_loss: 0.0694 - val_mae: 0.2238\n",
      "Epoch 188/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0703 - mae: 0.2265 - val_loss: 0.0693 - val_mae: 0.2250\n",
      "Epoch 189/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.0703 - mae: 0.2266 - val_loss: 0.0692 - val_mae: 0.2243\n",
      "Epoch 190/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0692 - val_mae: 0.2247\n",
      "Epoch 191/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.0701 - mae: 0.2262 - val_loss: 0.0693 - val_mae: 0.2250\n",
      "Epoch 192/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0693 - val_mae: 0.2249\n",
      "Epoch 193/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0700 - mae: 0.2261 - val_loss: 0.0693 - val_mae: 0.2251\n",
      "Epoch 194/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 0.0702 - mae: 0.2264 - val_loss: 0.0692 - val_mae: 0.2246\n",
      "Epoch 195/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0701 - mae: 0.2261 - val_loss: 0.0692 - val_mae: 0.2246\n",
      "Epoch 196/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.0703 - mae: 0.2265 - val_loss: 0.0692 - val_mae: 0.2248\n",
      "Epoch 197/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0700 - mae: 0.2261 - val_loss: 0.0692 - val_mae: 0.2246\n",
      "Epoch 198/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0702 - mae: 0.2265 - val_loss: 0.0692 - val_mae: 0.2243\n",
      "Epoch 199/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0700 - mae: 0.2262 - val_loss: 0.0692 - val_mae: 0.2242\n",
      "Epoch 200/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.0701 - mae: 0.2262 - val_loss: 0.0693 - val_mae: 0.2238\n",
      "Epoch 201/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0701 - mae: 0.2263 - val_loss: 0.0692 - val_mae: 0.2241\n",
      "Epoch 202/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0699 - mae: 0.2259 - val_loss: 0.0693 - val_mae: 0.2250\n",
      "Epoch 203/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.0702 - mae: 0.2264 - val_loss: 0.0693 - val_mae: 0.2239\n",
      "Epoch 204/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.0701 - mae: 0.2262 - val_loss: 0.0692 - val_mae: 0.2240\n",
      "Epoch 205/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.0701 - mae: 0.2261 - val_loss: 0.0692 - val_mae: 0.2242\n",
      "Epoch 206/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0701 - mae: 0.2261 - val_loss: 0.0693 - val_mae: 0.2252\n",
      "Epoch 207/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.0700 - mae: 0.2262 - val_loss: 0.0693 - val_mae: 0.2250\n",
      "Epoch 208/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0692 - val_mae: 0.2240\n",
      "Epoch 209/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0701 - mae: 0.2264 - val_loss: 0.0692 - val_mae: 0.2243\n",
      "Epoch 210/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0694 - val_mae: 0.2255\n",
      "Epoch 211/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0692 - val_mae: 0.2247\n",
      "Epoch 212/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.0703 - mae: 0.2266 - val_loss: 0.0692 - val_mae: 0.2239\n",
      "Epoch 213/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.0698 - mae: 0.2256 - val_loss: 0.0692 - val_mae: 0.2242\n",
      "Epoch 214/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0701 - mae: 0.2262 - val_loss: 0.0691 - val_mae: 0.2245\n",
      "Epoch 215/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0691 - val_mae: 0.2241\n",
      "Epoch 216/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0693 - val_mae: 0.2239\n",
      "Epoch 217/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0692 - val_mae: 0.2246\n",
      "Epoch 218/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0700 - mae: 0.2261 - val_loss: 0.0692 - val_mae: 0.2247\n",
      "Epoch 219/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0693 - val_mae: 0.2250\n",
      "Epoch 220/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.0702 - mae: 0.2265 - val_loss: 0.0691 - val_mae: 0.2243\n",
      "Epoch 221/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 0.0701 - mae: 0.2262 - val_loss: 0.0692 - val_mae: 0.2248\n",
      "Epoch 222/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - loss: 0.0701 - mae: 0.2263 - val_loss: 0.0691 - val_mae: 0.2241\n",
      "Epoch 223/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.0700 - mae: 0.2261 - val_loss: 0.0691 - val_mae: 0.2244\n",
      "Epoch 224/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.0701 - mae: 0.2260 - val_loss: 0.0691 - val_mae: 0.2242\n",
      "Epoch 225/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - loss: 0.0700 - mae: 0.2262 - val_loss: 0.0691 - val_mae: 0.2240\n",
      "Epoch 226/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0691 - val_mae: 0.2240\n",
      "Epoch 227/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0692 - val_mae: 0.2247\n",
      "Epoch 228/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0699 - mae: 0.2260 - val_loss: 0.0692 - val_mae: 0.2248\n",
      "Epoch 229/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0691 - val_mae: 0.2244\n",
      "Epoch 230/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - loss: 0.0701 - mae: 0.2261 - val_loss: 0.0692 - val_mae: 0.2247\n",
      "Epoch 231/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0699 - mae: 0.2259 - val_loss: 0.0692 - val_mae: 0.2247\n",
      "Epoch 232/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0702 - mae: 0.2264 - val_loss: 0.0691 - val_mae: 0.2240\n",
      "Epoch 233/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0699 - mae: 0.2259 - val_loss: 0.0692 - val_mae: 0.2240\n",
      "Epoch 234/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0692 - val_mae: 0.2247\n",
      "Epoch 235/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0699 - mae: 0.2259 - val_loss: 0.0691 - val_mae: 0.2243\n",
      "Epoch 236/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0691 - val_mae: 0.2247\n",
      "Epoch 237/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.0701 - mae: 0.2261 - val_loss: 0.0691 - val_mae: 0.2242\n",
      "Epoch 238/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.0698 - mae: 0.2257 - val_loss: 0.0691 - val_mae: 0.2240\n",
      "Epoch 239/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796us/step - loss: 0.0699 - mae: 0.2259 - val_loss: 0.0691 - val_mae: 0.2241\n",
      "Epoch 240/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0691 - val_mae: 0.2244\n",
      "Epoch 241/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0692 - val_mae: 0.2250\n",
      "Epoch 242/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.0698 - mae: 0.2258 - val_loss: 0.0691 - val_mae: 0.2242\n",
      "Epoch 243/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0691 - val_mae: 0.2239\n",
      "Epoch 244/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 0.0700 - mae: 0.2261 - val_loss: 0.0691 - val_mae: 0.2243\n",
      "Epoch 245/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0691 - val_mae: 0.2245\n",
      "Epoch 246/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 0.0699 - mae: 0.2259 - val_loss: 0.0691 - val_mae: 0.2243\n",
      "Epoch 247/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - loss: 0.0698 - mae: 0.2257 - val_loss: 0.0692 - val_mae: 0.2252\n",
      "Epoch 248/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - loss: 0.0699 - mae: 0.2259 - val_loss: 0.0691 - val_mae: 0.2240\n",
      "Epoch 249/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0693 - val_mae: 0.2252\n",
      "Epoch 250/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0691 - val_mae: 0.2243\n",
      "Epoch 251/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.0700 - mae: 0.2261 - val_loss: 0.0691 - val_mae: 0.2241\n",
      "Epoch 252/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 0.0700 - mae: 0.2261 - val_loss: 0.0691 - val_mae: 0.2240\n",
      "Epoch 253/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.0700 - mae: 0.2261 - val_loss: 0.0691 - val_mae: 0.2239\n",
      "Epoch 254/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0691 - val_mae: 0.2246\n",
      "Epoch 255/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0691 - val_mae: 0.2239\n",
      "Epoch 256/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0691 - val_mae: 0.2244\n",
      "Epoch 257/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - loss: 0.0701 - mae: 0.2263 - val_loss: 0.0690 - val_mae: 0.2240\n",
      "Epoch 258/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0690 - val_mae: 0.2240\n",
      "Epoch 259/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - loss: 0.0700 - mae: 0.2261 - val_loss: 0.0690 - val_mae: 0.2240\n",
      "Epoch 260/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0694 - val_mae: 0.2254\n",
      "Epoch 261/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0691 - val_mae: 0.2245\n",
      "Epoch 262/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.0702 - mae: 0.2264 - val_loss: 0.0691 - val_mae: 0.2241\n",
      "Epoch 263/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.0700 - mae: 0.2258 - val_loss: 0.0691 - val_mae: 0.2243\n",
      "Epoch 264/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0690 - val_mae: 0.2238\n",
      "Epoch 265/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0692 - val_mae: 0.2250\n",
      "Epoch 266/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.0701 - mae: 0.2262 - val_loss: 0.0691 - val_mae: 0.2244\n",
      "Epoch 267/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0690 - val_mae: 0.2242\n",
      "Epoch 268/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0690 - val_mae: 0.2243\n",
      "Epoch 269/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.0700 - mae: 0.2258 - val_loss: 0.0691 - val_mae: 0.2237\n",
      "Epoch 270/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.0698 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2241\n",
      "Epoch 271/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.0700 - mae: 0.2259 - val_loss: 0.0691 - val_mae: 0.2237\n",
      "Epoch 272/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.0701 - mae: 0.2261 - val_loss: 0.0690 - val_mae: 0.2239\n",
      "Epoch 273/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0690 - val_mae: 0.2243\n",
      "Epoch 274/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - loss: 0.0697 - mae: 0.2255 - val_loss: 0.0691 - val_mae: 0.2248\n",
      "Epoch 275/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0690 - val_mae: 0.2242\n",
      "Epoch 276/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0699 - mae: 0.2259 - val_loss: 0.0691 - val_mae: 0.2243\n",
      "Epoch 277/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0701 - mae: 0.2260 - val_loss: 0.0690 - val_mae: 0.2238\n",
      "Epoch 278/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.0700 - mae: 0.2259 - val_loss: 0.0691 - val_mae: 0.2248\n",
      "Epoch 279/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0690 - val_mae: 0.2243\n",
      "Epoch 280/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2240\n",
      "Epoch 281/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.0699 - mae: 0.2259 - val_loss: 0.0690 - val_mae: 0.2238\n",
      "Epoch 282/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0690 - val_mae: 0.2241\n",
      "Epoch 283/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.0700 - mae: 0.2259 - val_loss: 0.0690 - val_mae: 0.2241\n",
      "Epoch 284/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0700 - mae: 0.2259 - val_loss: 0.0690 - val_mae: 0.2242\n",
      "Epoch 285/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2239\n",
      "Epoch 286/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0698 - mae: 0.2256 - val_loss: 0.0691 - val_mae: 0.2248\n",
      "Epoch 287/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0691 - val_mae: 0.2247\n",
      "Epoch 288/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.0701 - mae: 0.2262 - val_loss: 0.0690 - val_mae: 0.2239\n",
      "Epoch 289/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2242\n",
      "Epoch 290/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - loss: 0.0698 - mae: 0.2256 - val_loss: 0.0690 - val_mae: 0.2239\n",
      "Epoch 291/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0690 - val_mae: 0.2237\n",
      "Epoch 292/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0700 - mae: 0.2258 - val_loss: 0.0690 - val_mae: 0.2238\n",
      "Epoch 293/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 0.0698 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2237\n",
      "Epoch 294/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0697 - mae: 0.2254 - val_loss: 0.0690 - val_mae: 0.2242\n",
      "Epoch 295/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.0697 - mae: 0.2254 - val_loss: 0.0690 - val_mae: 0.2240\n",
      "Epoch 296/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 0.0699 - mae: 0.2259 - val_loss: 0.0690 - val_mae: 0.2242\n",
      "Epoch 297/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0691 - val_mae: 0.2233\n",
      "Epoch 298/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0690 - val_mae: 0.2244\n",
      "Epoch 299/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0690 - val_mae: 0.2241\n",
      "Epoch 300/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0690 - val_mae: 0.2240\n",
      "Epoch 301/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0690 - val_mae: 0.2239\n",
      "Epoch 302/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.0698 - mae: 0.2256 - val_loss: 0.0690 - val_mae: 0.2243\n",
      "Epoch 303/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 0.0698 - mae: 0.2256 - val_loss: 0.0690 - val_mae: 0.2237\n",
      "Epoch 304/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0690 - val_mae: 0.2237\n",
      "Epoch 305/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0691 - val_mae: 0.2246\n",
      "Epoch 306/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.0700 - mae: 0.2259 - val_loss: 0.0690 - val_mae: 0.2239\n",
      "Epoch 307/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.0699 - mae: 0.2255 - val_loss: 0.0690 - val_mae: 0.2242\n",
      "Epoch 308/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0690 - val_mae: 0.2236\n",
      "Epoch 309/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 0.0701 - mae: 0.2260 - val_loss: 0.0691 - val_mae: 0.2249\n",
      "Epoch 310/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0690 - val_mae: 0.2237\n",
      "Epoch 311/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0701 - mae: 0.2261 - val_loss: 0.0690 - val_mae: 0.2238\n",
      "Epoch 312/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.0700 - mae: 0.2258 - val_loss: 0.0690 - val_mae: 0.2242\n",
      "Epoch 313/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2238\n",
      "Epoch 314/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.0700 - mae: 0.2258 - val_loss: 0.0692 - val_mae: 0.2251\n",
      "Epoch 315/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.0698 - mae: 0.2256 - val_loss: 0.0691 - val_mae: 0.2234\n",
      "Epoch 316/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.0697 - mae: 0.2254 - val_loss: 0.0690 - val_mae: 0.2238\n",
      "Epoch 317/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0701 - mae: 0.2260 - val_loss: 0.0691 - val_mae: 0.2233\n",
      "Epoch 318/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2238\n",
      "Epoch 319/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2240\n",
      "Epoch 320/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0700 - mae: 0.2259 - val_loss: 0.0690 - val_mae: 0.2239\n",
      "Epoch 321/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.0701 - mae: 0.2260 - val_loss: 0.0690 - val_mae: 0.2245\n",
      "Epoch 322/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0690 - val_mae: 0.2239\n",
      "Epoch 323/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0690 - val_mae: 0.2243\n",
      "Epoch 324/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.0700 - mae: 0.2258 - val_loss: 0.0693 - val_mae: 0.2253\n",
      "Epoch 325/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2238\n",
      "Epoch 326/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2242\n",
      "Epoch 327/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 0.0700 - mae: 0.2260 - val_loss: 0.0690 - val_mae: 0.2241\n",
      "Epoch 328/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0700 - mae: 0.2259 - val_loss: 0.0690 - val_mae: 0.2234\n",
      "Epoch 329/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2237\n",
      "Epoch 330/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2238\n",
      "Epoch 331/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0690 - val_mae: 0.2236\n",
      "Epoch 332/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 0.0700 - mae: 0.2258 - val_loss: 0.0690 - val_mae: 0.2235\n",
      "Epoch 333/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 334/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 335/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0692 - val_mae: 0.2248\n",
      "Epoch 336/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.0700 - mae: 0.2258 - val_loss: 0.0689 - val_mae: 0.2237\n",
      "Epoch 337/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 338/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0690 - val_mae: 0.2236\n",
      "Epoch 339/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0698 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 340/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0701 - mae: 0.2261 - val_loss: 0.0690 - val_mae: 0.2234\n",
      "Epoch 341/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0690 - val_mae: 0.2234\n",
      "Epoch 342/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0700 - mae: 0.2259 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 343/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 344/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 345/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0699 - mae: 0.2255 - val_loss: 0.0690 - val_mae: 0.2241\n",
      "Epoch 346/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2236\n",
      "Epoch 347/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2241\n",
      "Epoch 348/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0690 - val_mae: 0.2243\n",
      "Epoch 349/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0699 - mae: 0.2255 - val_loss: 0.0690 - val_mae: 0.2241\n",
      "Epoch 350/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0690 - val_mae: 0.2240\n",
      "Epoch 351/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2236\n",
      "Epoch 352/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.0700 - mae: 0.2258 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 353/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.0698 - mae: 0.2256 - val_loss: 0.0691 - val_mae: 0.2247\n",
      "Epoch 354/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0691 - val_mae: 0.2229\n",
      "Epoch 355/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 356/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0697 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 357/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0690 - val_mae: 0.2236\n",
      "Epoch 358/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.0698 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 359/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0690 - val_mae: 0.2241\n",
      "Epoch 360/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.0700 - mae: 0.2258 - val_loss: 0.0690 - val_mae: 0.2243\n",
      "Epoch 361/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.0700 - mae: 0.2259 - val_loss: 0.0689 - val_mae: 0.2236\n",
      "Epoch 362/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 363/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2234\n",
      "Epoch 364/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0690 - val_mae: 0.2234\n",
      "Epoch 365/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.0697 - mae: 0.2254 - val_loss: 0.0690 - val_mae: 0.2244\n",
      "Epoch 366/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 367/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0700 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2236\n",
      "Epoch 368/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 369/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 0.0697 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 370/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0698 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 371/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 372/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 0.0700 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2236\n",
      "Epoch 373/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2241\n",
      "Epoch 374/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 375/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0701 - mae: 0.2261 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 376/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2236\n",
      "Epoch 377/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 378/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 379/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2236\n",
      "Epoch 380/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 381/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0690 - val_mae: 0.2234\n",
      "Epoch 382/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.0700 - mae: 0.2258 - val_loss: 0.0690 - val_mae: 0.2233\n",
      "Epoch 383/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0692 - val_mae: 0.2230\n",
      "Epoch 384/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 385/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 386/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 387/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.0699 - mae: 0.2258 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 388/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.0697 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2242\n",
      "Epoch 389/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2237\n",
      "Epoch 390/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 391/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2241\n",
      "Epoch 392/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0691 - val_mae: 0.2248\n",
      "Epoch 393/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.0698 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 394/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0698 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2231\n",
      "Epoch 395/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 396/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 397/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0698 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 398/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 399/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2237\n",
      "Epoch 400/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2236\n",
      "Epoch 401/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 402/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.0700 - mae: 0.2259 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 403/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 404/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0690 - val_mae: 0.2231\n",
      "Epoch 405/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0691 - val_mae: 0.2231\n",
      "Epoch 406/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 0.0700 - mae: 0.2259 - val_loss: 0.0689 - val_mae: 0.2236\n",
      "Epoch 407/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 408/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2241\n",
      "Epoch 409/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0697 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 410/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 411/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 412/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.0697 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2237\n",
      "Epoch 413/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0699 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 414/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2237\n",
      "Epoch 415/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.0698 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2234\n",
      "Epoch 416/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 417/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0690 - val_mae: 0.2243\n",
      "Epoch 418/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0691 - val_mae: 0.2249\n",
      "Epoch 419/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.0698 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 420/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2234\n",
      "Epoch 421/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 422/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 423/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2234\n",
      "Epoch 424/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0690 - val_mae: 0.2245\n",
      "Epoch 425/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2234\n",
      "Epoch 426/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0690 - val_mae: 0.2243\n",
      "Epoch 427/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2242\n",
      "Epoch 428/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2246\n",
      "Epoch 429/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2236\n",
      "Epoch 430/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0700 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 431/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2237\n",
      "Epoch 432/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 433/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2237\n",
      "Epoch 434/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2234\n",
      "Epoch 435/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2234\n",
      "Epoch 436/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2236\n",
      "Epoch 437/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 438/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2237\n",
      "Epoch 439/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2234\n",
      "Epoch 440/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 441/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2241\n",
      "Epoch 442/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 443/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 444/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2234\n",
      "Epoch 445/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2237\n",
      "Epoch 446/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0690 - val_mae: 0.2229\n",
      "Epoch 447/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 448/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 449/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2241\n",
      "Epoch 450/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0698 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 451/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.0695 - mae: 0.2248 - val_loss: 0.0689 - val_mae: 0.2237\n",
      "Epoch 452/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 453/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2236\n",
      "Epoch 454/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 455/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0700 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 456/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0699 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 457/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2237\n",
      "Epoch 458/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 459/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2234\n",
      "Epoch 460/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.0699 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2231\n",
      "Epoch 461/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0690 - val_mae: 0.2246\n",
      "Epoch 462/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0690 - val_mae: 0.2244\n",
      "Epoch 463/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2232\n",
      "Epoch 464/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2233\n",
      "Epoch 465/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 466/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2237\n",
      "Epoch 467/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0700 - mae: 0.2257 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 468/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2231\n",
      "Epoch 469/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2234\n",
      "Epoch 470/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 471/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 472/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 0.0697 - mae: 0.2250 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 473/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0689 - val_mae: 0.2235\n",
      "Epoch 474/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0690 - val_mae: 0.2245\n",
      "Epoch 475/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 476/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0695 - mae: 0.2248 - val_loss: 0.0689 - val_mae: 0.2233\n",
      "Epoch 477/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2232\n",
      "Epoch 478/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0690 - val_mae: 0.2229\n",
      "Epoch 479/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0690 - val_mae: 0.2245\n",
      "Epoch 480/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.0699 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 481/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 482/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0690 - val_mae: 0.2228\n",
      "Epoch 483/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0698 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2232\n",
      "Epoch 484/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 485/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 486/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0699 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 487/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 0.0700 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2231\n",
      "Epoch 488/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2245\n",
      "Epoch 489/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 490/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 491/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2231\n",
      "Epoch 492/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.0695 - mae: 0.2248 - val_loss: 0.0689 - val_mae: 0.2233\n",
      "Epoch 493/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.0699 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2231\n",
      "Epoch 494/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0691 - val_mae: 0.2246\n",
      "Epoch 495/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0700 - mae: 0.2257 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 496/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2237\n",
      "Epoch 497/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 498/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2234\n",
      "Epoch 499/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 500/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.0698 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 501/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 502/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.0699 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 503/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 504/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 505/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 506/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0690 - val_mae: 0.2231\n",
      "Epoch 507/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0700 - mae: 0.2256 - val_loss: 0.0688 - val_mae: 0.2237\n",
      "Epoch 508/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 509/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0690 - val_mae: 0.2244\n",
      "Epoch 510/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 511/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2236\n",
      "Epoch 512/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 513/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0697 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 514/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 515/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 516/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0698 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2229\n",
      "Epoch 517/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0697 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 518/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.0698 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 519/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2237\n",
      "Epoch 520/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2232\n",
      "Epoch 521/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0696 - mae: 0.2248 - val_loss: 0.0688 - val_mae: 0.2238\n",
      "Epoch 522/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 523/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2243\n",
      "Epoch 524/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 525/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.0699 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 526/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0689 - val_mae: 0.2242\n",
      "Epoch 527/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 528/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0689 - val_mae: 0.2244\n",
      "Epoch 529/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2238\n",
      "Epoch 530/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2233\n",
      "Epoch 531/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 532/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.0696 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2233\n",
      "Epoch 533/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2231\n",
      "Epoch 534/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 535/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 536/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2242\n",
      "Epoch 537/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2233\n",
      "Epoch 538/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0688 - val_mae: 0.2229\n",
      "Epoch 539/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0688 - val_mae: 0.2238\n",
      "Epoch 540/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2232\n",
      "Epoch 541/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 542/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2230\n",
      "Epoch 543/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0689 - val_mae: 0.2231\n",
      "Epoch 544/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2237\n",
      "Epoch 545/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.0698 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2239\n",
      "Epoch 546/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2230\n",
      "Epoch 547/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 548/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2239\n",
      "Epoch 549/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2243\n",
      "Epoch 550/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 551/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2238\n",
      "Epoch 552/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 553/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 554/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 555/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2239\n",
      "Epoch 556/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 557/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 558/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 559/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0688 - val_mae: 0.2232\n",
      "Epoch 560/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 561/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 562/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2239\n",
      "Epoch 563/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.0695 - mae: 0.2249 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 564/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0689 - val_mae: 0.2232\n",
      "Epoch 565/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 566/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0689 - val_mae: 0.2233\n",
      "Epoch 567/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2232\n",
      "Epoch 568/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - loss: 0.0694 - mae: 0.2246 - val_loss: 0.0688 - val_mae: 0.2238\n",
      "Epoch 569/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2237\n",
      "Epoch 570/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2237\n",
      "Epoch 571/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0690 - val_mae: 0.2230\n",
      "Epoch 572/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2240\n",
      "Epoch 573/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 574/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2232\n",
      "Epoch 575/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0692 - val_mae: 0.2251\n",
      "Epoch 576/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0691 - val_mae: 0.2228\n",
      "Epoch 577/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 578/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2237\n",
      "Epoch 579/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0689 - val_mae: 0.2241\n",
      "Epoch 580/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2228\n",
      "Epoch 581/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 582/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2237\n",
      "Epoch 583/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 584/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0695 - mae: 0.2248 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 585/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 586/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.0699 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 587/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 588/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 589/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 590/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 591/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0695 - mae: 0.2249 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 592/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.0700 - mae: 0.2257 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 593/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 594/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0688 - val_mae: 0.2238\n",
      "Epoch 595/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 596/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2228\n",
      "Epoch 597/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2233\n",
      "Epoch 598/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 599/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2233\n",
      "Epoch 600/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2241\n",
      "Epoch 601/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 602/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2232\n",
      "Epoch 603/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 604/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2232\n",
      "Epoch 605/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 606/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2237\n",
      "Epoch 607/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 608/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0699 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2242\n",
      "Epoch 609/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 610/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 611/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2230\n",
      "Epoch 612/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2233\n",
      "Epoch 613/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0690 - val_mae: 0.2245\n",
      "Epoch 614/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 615/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0689 - val_mae: 0.2239\n",
      "Epoch 616/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2232\n",
      "Epoch 617/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.0697 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 618/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.0695 - mae: 0.2248 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 619/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 620/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 621/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2230\n",
      "Epoch 622/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0689 - val_mae: 0.2245\n",
      "Epoch 623/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0689 - val_mae: 0.2242\n",
      "Epoch 624/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 625/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0688 - val_mae: 0.2237\n",
      "Epoch 626/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2233\n",
      "Epoch 627/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2240\n",
      "Epoch 628/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2233\n",
      "Epoch 629/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0697 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2232\n",
      "Epoch 630/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2240\n",
      "Epoch 631/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 632/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 633/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2239\n",
      "Epoch 634/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2233\n",
      "Epoch 635/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.0700 - mae: 0.2256 - val_loss: 0.0688 - val_mae: 0.2233\n",
      "Epoch 636/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 637/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 638/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 639/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.0699 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 640/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 641/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2237\n",
      "Epoch 642/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.0699 - mae: 0.2257 - val_loss: 0.0688 - val_mae: 0.2229\n",
      "Epoch 643/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0695 - mae: 0.2248 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 644/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2229\n",
      "Epoch 645/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 646/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 647/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2233\n",
      "Epoch 648/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2238\n",
      "Epoch 649/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2228\n",
      "Epoch 650/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 651/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2233\n",
      "Epoch 652/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0688 - val_mae: 0.2238\n",
      "Epoch 653/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 654/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 655/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.0698 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 656/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2228\n",
      "Epoch 657/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 658/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 659/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2239\n",
      "Epoch 660/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 661/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 662/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.0695 - mae: 0.2248 - val_loss: 0.0688 - val_mae: 0.2233\n",
      "Epoch 663/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 664/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 665/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0689 - val_mae: 0.2241\n",
      "Epoch 666/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 667/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 668/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 669/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 670/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0688 - val_mae: 0.2237\n",
      "Epoch 671/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2229\n",
      "Epoch 672/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 673/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 674/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 675/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 676/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0697 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 677/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0689 - val_mae: 0.2242\n",
      "Epoch 678/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2232\n",
      "Epoch 679/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 680/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0689 - val_mae: 0.2228\n",
      "Epoch 681/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2227\n",
      "Epoch 682/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 683/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2239\n",
      "Epoch 684/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.0695 - mae: 0.2248 - val_loss: 0.0688 - val_mae: 0.2232\n",
      "Epoch 685/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 686/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.0695 - mae: 0.2249 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 687/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2233\n",
      "Epoch 688/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0699 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 689/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2238\n",
      "Epoch 690/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.0699 - mae: 0.2256 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 691/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2232\n",
      "Epoch 692/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 693/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.0697 - mae: 0.2250 - val_loss: 0.0689 - val_mae: 0.2229\n",
      "Epoch 694/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2227\n",
      "Epoch 695/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0689 - val_mae: 0.2225\n",
      "Epoch 696/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0696 - mae: 0.2248 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 697/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.0695 - mae: 0.2248 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 698/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2233\n",
      "Epoch 699/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 0.0694 - mae: 0.2246 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 700/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0689 - val_mae: 0.2241\n",
      "Epoch 701/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0698 - mae: 0.2255 - val_loss: 0.0688 - val_mae: 0.2228\n",
      "Epoch 702/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 793us/step - loss: 0.0695 - mae: 0.2246 - val_loss: 0.0688 - val_mae: 0.2229\n",
      "Epoch 703/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2229\n",
      "Epoch 704/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2239\n",
      "Epoch 705/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2234\n",
      "Epoch 706/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 707/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0687 - val_mae: 0.2233\n",
      "Epoch 708/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0691 - val_mae: 0.2225\n",
      "Epoch 709/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0689 - val_mae: 0.2244\n",
      "Epoch 710/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2227\n",
      "Epoch 711/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0697 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 712/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2226\n",
      "Epoch 713/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0687 - val_mae: 0.2233\n",
      "Epoch 714/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0687 - val_mae: 0.2231\n",
      "Epoch 715/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0697 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2240\n",
      "Epoch 716/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 717/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.0696 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 718/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 0.0695 - mae: 0.2247 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 719/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 720/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2232\n",
      "Epoch 721/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - loss: 0.0695 - mae: 0.2247 - val_loss: 0.0688 - val_mae: 0.2237\n",
      "Epoch 722/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0687 - val_mae: 0.2233\n",
      "Epoch 723/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 724/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - loss: 0.0695 - mae: 0.2248 - val_loss: 0.0688 - val_mae: 0.2232\n",
      "Epoch 725/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.0695 - mae: 0.2249 - val_loss: 0.0687 - val_mae: 0.2231\n",
      "Epoch 726/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.0695 - mae: 0.2248 - val_loss: 0.0687 - val_mae: 0.2232\n",
      "Epoch 727/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 728/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2240\n",
      "Epoch 729/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0687 - val_mae: 0.2229\n",
      "Epoch 730/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 731/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0694 - mae: 0.2246 - val_loss: 0.0688 - val_mae: 0.2229\n",
      "Epoch 732/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0687 - val_mae: 0.2233\n",
      "Epoch 733/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.0698 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2228\n",
      "Epoch 734/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0688 - val_mae: 0.2229\n",
      "Epoch 735/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.0695 - mae: 0.2248 - val_loss: 0.0687 - val_mae: 0.2232\n",
      "Epoch 736/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0688 - val_mae: 0.2238\n",
      "Epoch 737/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0687 - val_mae: 0.2234\n",
      "Epoch 738/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0687 - val_mae: 0.2231\n",
      "Epoch 739/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0698 - mae: 0.2252 - val_loss: 0.0687 - val_mae: 0.2231\n",
      "Epoch 740/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2239\n",
      "Epoch 741/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.0695 - mae: 0.2247 - val_loss: 0.0688 - val_mae: 0.2239\n",
      "Epoch 742/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0687 - val_mae: 0.2235\n",
      "Epoch 743/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0687 - val_mae: 0.2230\n",
      "Epoch 744/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.0698 - mae: 0.2253 - val_loss: 0.0687 - val_mae: 0.2233\n",
      "Epoch 745/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0687 - val_mae: 0.2231\n",
      "Epoch 746/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0698 - mae: 0.2251 - val_loss: 0.0688 - val_mae: 0.2228\n",
      "Epoch 747/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0688 - val_mae: 0.2226\n",
      "Epoch 748/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.0699 - mae: 0.2254 - val_loss: 0.0688 - val_mae: 0.2237\n",
      "Epoch 749/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0687 - val_mae: 0.2234\n",
      "Epoch 750/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0690 - val_mae: 0.2241\n",
      "Epoch 751/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0687 - val_mae: 0.2233\n",
      "Epoch 752/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 0.0697 - mae: 0.2253 - val_loss: 0.0689 - val_mae: 0.2225\n",
      "Epoch 753/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.0698 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2237\n",
      "Epoch 754/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0695 - mae: 0.2247 - val_loss: 0.0689 - val_mae: 0.2228\n",
      "Epoch 755/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2239\n",
      "Epoch 756/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 0.0697 - mae: 0.2252 - val_loss: 0.0688 - val_mae: 0.2236\n",
      "Epoch 757/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0689 - val_mae: 0.2225\n",
      "Epoch 758/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.0697 - mae: 0.2251 - val_loss: 0.0687 - val_mae: 0.2232\n",
      "Epoch 759/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0695 - mae: 0.2249 - val_loss: 0.0687 - val_mae: 0.2232\n",
      "Epoch 760/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0696 - mae: 0.2249 - val_loss: 0.0688 - val_mae: 0.2230\n",
      "Epoch 761/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.0696 - mae: 0.2250 - val_loss: 0.0687 - val_mae: 0.2229\n",
      "Epoch 762/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0695 - mae: 0.2247 - val_loss: 0.0688 - val_mae: 0.2235\n",
      "Epoch 763/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.0694 - mae: 0.2246 - val_loss: 0.0688 - val_mae: 0.2231\n",
      "Epoch 764/1000\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0694 - mae: 0.2247 - val_loss: 0.0688 - val_mae: 0.2228\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network model\n",
    "print(\"Building the neural network model...\")\n",
    "model = build_model(X.shape[1])\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',         # Monitor the validation loss\n",
    "    patience=20,                # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True   # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")\n",
    "\n",
    "# Train the model with early stopping\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(\n",
    "    X_normalized, \n",
    "    y_normalized, \n",
    "    epochs=1000,               # Set a large number of epochs\n",
    "    batch_size=1000,\n",
    "    validation_split=0.2, \n",
    "    callbacks=[early_stopping],  # Include the early stopping callback\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c48389bf-7c49-4c69-8299-9600d696c83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation loss\n",
    "plot_loss(history, filename='loss_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31862d5f-bb7a-4c88-a17b-d425755966e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('plastic_strain_predictor_model_abs_24_11.h5')\n",
    "#print(\"Model saved as 'plastic_strain_predictor_model.h5'\")\n",
    "\n",
    "with open('scaler_X_abs.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_X, file)\n",
    "with open('scaler_y_abs.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_y, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6313c2-53bf-4d29-b584-9eadbcdd5378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9616e7ea-c008-4a7d-a6fe-05bc15cdbb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e191314e-2c97-4b7e-ad00-6b7e1e55fed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32db745-a05a-4b83-9242-1c8335694898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415bbce-793d-483f-97d8-fc42c3cc09dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39528c10-28f7-4371-bb00-73e80cec62c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
